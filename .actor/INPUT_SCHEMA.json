{
  "title": "Input schema for n8n API docs crawler",
  "description": "Enter the start URL(s) of the website(s) to crawl, configure other optional settings, and run the Actor to crawl the pages and extract their endpoints",
  "type": "object",
  "schemaVersion": 1,
  "properties": {
      "startUrl": {
          "title": "Start URLs",
          "type": "string",
          "description": "One or more URLs of the pages where the crawler will start. Note that the Actor will additionally only crawl sub-pages of these URLs. For example, for the start URL `https://www.example.com/blog`, it will crawl pages like `https://example.com/blog/article-1`, but will skip `https://example.com/docs/something-else`.",
          "editor": "textfield",
          "prefill": "https://developer.benchmarkemail.com/"
      },
      "docsType": {
          "sectionCaption": "Crawler settings",
          "title": "Crawler type",
          "type": "string",
          "editor": "select",
          "enum": ["singlePage", "individualPages", "singlePageSections", "swagger"],
          "enumTitles": ["Single Page with Flat(Non-Nested) Structure", "Multi-Page", "Single Page with Nested Sections", "Swagger Docs"],
          "description": "Select the type of the website you want to crawl. The crawler will use different strategies to extract the endpoints based on the type of the website.",
          "default": "singlePage"
      },
      "name": {
          "title": "Name",
          "type": "string",
          "editor": "textfield",
          "description": "The name of the service.",
          "prefill": ""
      },
      "globs": {
          "title": "Globs",
          "type": "array",
          "editor": "json",
          "description": "A list of globs that will be used to filter out URLs from the crawl. The globs are matched against the URLs of the crawled pages. If a glob matches, the page is not crawled. For example, to skip all pages that contain `/blog/` in their URL, use the glob `/blog/*`.",
          "prefill": ["**/reference/**"]
      },
      "globs_exclude": {
          "title": "Globs exclude",
          "type": "array",
          "editor": "json",
          "description": "A list of globs that will be used to filter out URLs from the crawl. The globs are matched against the URLs of the crawled pages. If a glob matches, the page is not crawled. For example, to skip all pages that contain `/blog/` in their URL, use the glob `/blog/*`.",
          "prefill": []
      },
      "clickSelector": {
          "title": "Click selector",
          "type": "string",
          "editor": "textfield",
          "description": "A CSS selector of the element that the crawler will click on before extracting the endpoints. This setting is useful for websites that load their content dynamically. For example, if the website loads its content after clicking on a button, enter the CSS selector of the button here.",
          "prefill": ""
      },
      "sectionsDelimiterSelector": {
          "title": "Sections delimiter selector",
          "type": "string",
          "editor": "textfield",
          "description": "A CSS selector of the element that separates the sections of the documentation. The crawler will extract the endpoints from each section separately. This setting is useful for websites that have a single page with multiple sections, for example, a page with multiple API versions.",
          "prefill": ""
      },
      "nameSelector": {
          "title": "Name selector",
          "type": "string",
          "editor": "textfield",
          "description": "A CSS selector of the element that contains the name of the endpoint. The crawler will extract the text from this element and use it as the name of the endpoint. This setting is useful for websites that have the name of the endpoint in a separate element, for example, in a `<h1>` tag.",
          "prefill": ""
      },
      "maxCrawlDepth": {
          "title": "Max crawling depth",
          "type": "integer",
          "editor": "number",
          "description": "The maximum number of links starting from the start URL that the crawler will recursively descend. The start URLs have a depth of 0, the pages linked directly from the start URLs have a depth of 1, and so on.\n\nThis setting is useful to prevent accidental crawler runaway. By setting it to 0, the Actor will only crawl start URLs.",
          "minimum": 0,
          "default": 20
      },
      "maxCrawlPages": {
          "title": "Max pages",
          "type": "integer",
          "editor": "number",
          "description": "The maximum number pages to crawl. It includes the start URLs, pagination pages, pages with no content, etc. The crawler will automatically finish after reaching this number. This setting is useful to prevent accidental crawler runaway.",
          "minimum": 0,
          "default": 9999999
      }
  }
}